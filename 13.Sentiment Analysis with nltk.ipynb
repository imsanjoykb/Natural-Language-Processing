{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with `nltk.sentiment.SentimentAnalyzer` and VADER tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploring the `subjectivity` corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot.tok.gt9.5000', 'quote.tok.gt9.5000']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import subjectivity\n",
    "\n",
    "subjectivity.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'movie', 'begins', 'in', 'the', 'past', 'where', 'a', 'young', 'boy', 'named', 'sam', 'attempts', 'to', 'save', 'celebi', 'from', 'a', 'hunter', '.'], ['emerging', 'from', 'the', 'human', 'psyche', 'and', 'showing', 'characteristics', 'of', 'abstract', 'expressionism', ',', 'minimalism', 'and', 'russian', 'constructivism', ',', 'graffiti', 'removal', 'has', 'secured', 'its', 'place', 'in', 'the', 'history', 'of', 'modern', 'art', 'while', 'being', 'created', 'by', 'artists', 'who', 'are', 'unconscious', 'of', 'their', 'artistic', 'achievements', '.'], ...]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity.sents('plot.tok.gt9.5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['smart', 'and', 'alert', ',', 'thirteen', 'conversations', 'about', 'one', 'thing', 'is', 'a', 'small', 'gem', '.'], ['color', ',', 'musical', 'bounce', 'and', 'warm', 'seas', 'lapping', 'on', 'island', 'shores', '.', 'and', 'just', 'enough', 'science', 'to', 'send', 'you', 'home', 'thinking', '.'], ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity.sents('quote.tok.gt9.5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['obj', 'subj']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity.categories() # The mapping between documents and categories does not depend on the file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the', 'movie', 'begins', 'in', 'the', 'past', 'where', 'a', 'young', 'boy', 'named', 'sam', 'attempts', 'to', 'save', 'celebi', 'from', 'a', 'hunter', '.'], ['emerging', 'from', 'the', 'human', 'psyche', 'and', 'showing', 'characteristics', 'of', 'abstract', 'expressionism', ',', 'minimalism', 'and', 'russian', 'constructivism', ',', 'graffiti', 'removal', 'has', 'secured', 'its', 'place', 'in', 'the', 'history', 'of', 'modern', 'art', 'while', 'being', 'created', 'by', 'artists', 'who', 'are', 'unconscious', 'of', 'their', 'artistic', 'achievements', '.'], ...]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity.sents(categories='obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['smart', 'and', 'alert', ',', 'thirteen', 'conversations', 'about', 'one', 'thing', 'is', 'a', 'small', 'gem', '.'], ['color', ',', 'musical', 'bounce', 'and', 'warm', 'seas', 'lapping', 'on', 'island', 'shores', '.', 'and', 'just', 'enough', 'science', 'to', 'send', 'you', 'home', 'thinking', '.'], ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity.sents(categories='subj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building and testing a classifier with `SentimentAnalyzer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.sentiment import SentimentAnalyzer # SentimentAnalyzer is a tool to implement and facilitate Sentiment Analysis.\n",
    "from nltk.sentiment.util import (mark_negation, extract_unigram_feats) # mark_negation(): Append _NEG suffix to words that appear in the scope between a negation and a punctuation mark. extract_unigram_feats(): Populate a dictionary of unigram features, reflecting the presence/absence in the document of each of the tokens in unigrams.\n",
    "\n",
    "n_instances = 100\n",
    "obj_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\n",
    "subj_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
    "len(obj_docs), len(subj_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'movie',\n",
       "  'begins',\n",
       "  'in',\n",
       "  'the',\n",
       "  'past',\n",
       "  'where',\n",
       "  'a',\n",
       "  'young',\n",
       "  'boy',\n",
       "  'named',\n",
       "  'sam',\n",
       "  'attempts',\n",
       "  'to',\n",
       "  'save',\n",
       "  'celebi',\n",
       "  'from',\n",
       "  'a',\n",
       "  'hunter',\n",
       "  '.'],\n",
       " 'obj')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_obj_docs = obj_docs[:80]\n",
    "test_obj_docs = obj_docs[80:100]\n",
    "train_subj_docs = subj_docs[:80]\n",
    "test_subj_docs = subj_docs[80:100]\n",
    "\n",
    "training_docs = train_obj_docs + train_subj_docs\n",
    "testing_docs = test_obj_docs + test_subj_docs\n",
    "\n",
    "sentim_analyzer = SentimentAnalyzer()\n",
    "all_words_neg = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_feats = sentim_analyzer.unigram_word_feats(all_words_neg, min_freq=4)\n",
    "len(unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'contains(\")': False,\n",
       "  'contains(()': False,\n",
       "  'contains())': False,\n",
       "  'contains(,)': False,\n",
       "  'contains(,_NEG)': False,\n",
       "  'contains(--)': False,\n",
       "  'contains(.)': True,\n",
       "  'contains(:)': False,\n",
       "  'contains(;)': False,\n",
       "  'contains(a)': True,\n",
       "  'contains(a_NEG)': False,\n",
       "  'contains(about)': False,\n",
       "  'contains(all)': False,\n",
       "  'contains(an)': False,\n",
       "  'contains(and)': False,\n",
       "  'contains(are)': False,\n",
       "  'contains(as)': False,\n",
       "  'contains(at)': False,\n",
       "  'contains(be)': False,\n",
       "  'contains(begins)': True,\n",
       "  'contains(both)': False,\n",
       "  'contains(but)': False,\n",
       "  'contains(but_NEG)': False,\n",
       "  'contains(by)': False,\n",
       "  'contains(can)': False,\n",
       "  'contains(even)': False,\n",
       "  'contains(film)': False,\n",
       "  'contains(for)': False,\n",
       "  'contains(from)': True,\n",
       "  'contains(has)': False,\n",
       "  'contains(have)': False,\n",
       "  'contains(he)': False,\n",
       "  'contains(her)': False,\n",
       "  'contains(him)': False,\n",
       "  'contains(his)': False,\n",
       "  'contains(home)': False,\n",
       "  'contains(if)': False,\n",
       "  'contains(in)': True,\n",
       "  'contains(into)': False,\n",
       "  'contains(is)': False,\n",
       "  \"contains(it's)\": False,\n",
       "  'contains(it)': False,\n",
       "  'contains(its)': False,\n",
       "  'contains(life)': False,\n",
       "  'contains(like)': False,\n",
       "  'contains(look)': False,\n",
       "  'contains(love)': False,\n",
       "  'contains(made)': False,\n",
       "  'contains(make)': False,\n",
       "  'contains(more)': False,\n",
       "  'contains(most)': False,\n",
       "  'contains(movie)': True,\n",
       "  'contains(not)': False,\n",
       "  'contains(of)': False,\n",
       "  'contains(of_NEG)': False,\n",
       "  'contains(on)': False,\n",
       "  'contains(one)': False,\n",
       "  'contains(only)': False,\n",
       "  'contains(out)': False,\n",
       "  'contains(search)': False,\n",
       "  'contains(she)': False,\n",
       "  'contains(so)': False,\n",
       "  'contains(some)': False,\n",
       "  'contains(story)': False,\n",
       "  'contains(that)': False,\n",
       "  'contains(the)': True,\n",
       "  'contains(the_NEG)': False,\n",
       "  'contains(their)': False,\n",
       "  'contains(them)': False,\n",
       "  \"contains(there's)\": False,\n",
       "  'contains(they)': False,\n",
       "  'contains(this)': False,\n",
       "  'contains(to)': True,\n",
       "  'contains(to_NEG)': False,\n",
       "  'contains(two)': False,\n",
       "  'contains(what)': False,\n",
       "  'contains(when)': False,\n",
       "  'contains(where)': True,\n",
       "  'contains(which)': False,\n",
       "  'contains(who)': False,\n",
       "  'contains(will)': False,\n",
       "  'contains(with)': False,\n",
       "  'contains(you)': False},\n",
       " 'obj')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = sentim_analyzer.apply_features(training_docs)\n",
    "test_set = sentim_analyzer.apply_features(testing_docs)\n",
    "training_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating NaiveBayesClassifier results...\n",
      "Accuracy: 0.8\n",
      "F-measure [obj]: 0.8\n",
      "F-measure [subj]: 0.8\n",
      "Precision [obj]: 0.8\n",
      "Precision [subj]: 0.8\n",
      "Recall [obj]: 0.8\n",
      "Recall [subj]: 0.8\n"
     ]
    }
   ],
   "source": [
    "for key,value in sorted(sentim_analyzer.evaluate(test_set).items()):\n",
    "    print('{0}: {1}'.format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sentiment analysis with `nltk.sentiment.vader.SentimentIntensityAnalyzer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a piece of shit, and I will step on you.\n",
      "compound: -0.5574, neg: 0.286, neu: 0.714, pos: 0.0, \n",
      "THIS SUX!!!\n",
      "compound: -0.5229, neg: 0.771, neu: 0.229, pos: 0.0, \n",
      "This kinda sux...\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "You're good, man\n",
      "compound: 0.4404, neg: 0.0, neu: 0.408, pos: 0.592, \n",
      "HAHAHA YOU ARE THE BEST!!!!! VERY FUNNY!!!\n",
      "compound: 0.8386, neg: 0.0, neu: 0.386, pos: 0.614, "
     ]
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "sentences = [\n",
    "    \"You are a piece of shit, and I will step on you.\",\n",
    "    \"THIS SUX!!!\",\n",
    "    \"This kinda sux...\",\n",
    "    \"You're good, man\",\n",
    "    \"HAHAHA YOU ARE THE BEST!!!!! VERY FUNNY!!!\"\n",
    "            ]\n",
    "\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for sentence in sentences:\n",
    "    print('\\n' + sentence)\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    for k in sorted(ss):\n",
    "        print('{0}: {1}, '.format(k, ss[k]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, `compound` represents the aggregated, final score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
